'''TowersOfHanoi.py
'''
#<METADATA>
QUIET_VERSION = "0.2"
PROBLEM_NAME = "Towers of Hanoi"
PROBLEM_VERSION = "0.4"
PROBLEM_AUTHORS = ['S. Tanimoto']
PROBLEM_CREATION_DATE = "14-JAN-2018"
PROBLEM_DESC=\
'''This formulation of the Towers of Hanoi problem uses generic
Python 3 constructs and has been tested with Python 3.6.
It is designed to work according to the QUIET2 tools interface.

This formulation is slightly different from others of this puzzle,
with some reordering of operators for better compatibility with
the Reinforcement Learning software.
The goal test is also different, but should function fine
with other tools.
'''
#</METADATA>

#<COMMON_DATA>
N_disks = 3  # Use default, but override if new value supplied
             # by the user on the command line.
try:
  import sys
  arg2 = sys.argv[2]
  N_disks = int(arg2)
  #print("Number of disks is "+arg2)
except:
  pass
  #print("Using default number of disks: "+str(N_disks))
  #print(" (To use a specific number, enter it on the command line, e.g.,")
  #print("python3 ../Int_Solv_Client.py TowersOfHanoi 3")
#</COMMON_DATA>

#<COMMON_CODE>
class State:
  def __init__(self, d):
    self.d = d

  def __eq__(self,s2):
    for p in ['peg1','peg2','peg3']:
      if self.d[p] != s2.d[p]: return False
    return True

  def __str__(self):
    # Produces a textual description of a state.
    # Might not be needed in normal operation with GUIs.
    txt = "["
    for peg in ['peg1','peg2','peg3']:
      txt += str(self.d[peg]) + " ,"
    return txt[:-2]+"]"

  def __hash__(self):
    return (self.__str__()).__hash__()

  def copy(self):
    # Performs an appropriately deep copy of a state,
    # for use by operators in creating new states.
    news = State({})
    for peg in ['peg1', 'peg2', 'peg3']:
      news.d[peg]=self.d[peg][:]
    return news

  def can_move(self,From,To):
    '''Tests whether it's legal to move a disk in state s
       from the From peg to the To peg.'''
    try:
      pf=self.d[From] # peg disk goes from
      pt=self.d[To]   # peg disk goes to
      if pf==[]: return False  # no disk to move.
      df=pf[-1]  # get topmost disk at From peg..
      if pt==[]: return True # no disk to worry about at To peg.
      dt=pt[-1]  # get topmost disk at To peg.
      if df<dt: return True # Disk is smaller than one it goes on.
      return False # Disk too big for one it goes on.
    except (Exception) as e:
      print(e)

  def move(self,From,To):
    '''Assuming it's legal to make the move, this computes
       the new state resulting from moving the topmost disk
       from the From peg to the To peg.'''
    news = self.copy() # start with a deep copy.
    pf=self.d[From] # peg disk goes from.
    pt=self.d[To]
    df=pf[-1]  # the disk to move.
    news.d[From]=pf[:-1] # remove it from its old peg.
    news.d[To]=pt[:]+[df] # Put disk onto destination peg.
    return news # return new state

def make_goal_state():
  global GOAL_STATE, N_disks
  GOAL_STATE = State({'peg1':[],'peg2':[],'peg3':list(range(N_disks,0,-1))})
  #print("GOAL_STATE="+str(GOAL_STATE))

make_goal_state()

def goal_test(s):
  '''Made stricter for use in Reinforcement Learning app.
  If the third peg has all N_disk disks on it, then s is a goal state.'''
  #return len(s.d['peg3'])==N_disks
  global GOAL_STATE
  return s==GOAL_STATE

def goal_message(s):
  return "The Tower Transport is Triumphant!"

class Operator:
  def __init__(self, name, precond, state_transf):
    self.name = name
    self.precond = precond
    self.state_transf = state_transf

  def is_applicable(self, s):
    return self.precond(s)

  def apply(self, s):
    return self.state_transf(s)

#</COMMON_CODE>

#<INITIAL_STATE>
#  INITIAL_DICT = {'peg1': list(range(N_disks,0,-1)), 'peg2':[], 'peg3':[] }
#  CREATE_INITIAL_STATE = lambda: State(INITIAL_DICT)
#DUMMY_STATE =  {'peg1':[], 'peg2':[], 'peg3':[] }
def CREATE_INITIAL_STATE():
  return State({'peg1': list(range(N_disks,0,-1)), 'peg2':[], 'peg3':[] })
#</INITIAL_STATE>

#<OPERATORS>
peg_combinations = [('peg'+str(a),'peg'+str(b)) for (a,b) in
#                    [(1,2),(1,3),(2,1),(2,3),(3,1),(3,2)]]
                    [(1,3),(1,2),(3,2),(3,1),(2,1),(2,3)]] # reordered for
                     # easier policy display in the Reinforcement Learning app.
OPERATORS = [Operator("Move disk from "+p+" to "+q,
                      lambda s,p1=p,q1=q: s.can_move(p1,q1),
                      # The default value construct is needed
                      # here to capture the values of p&q separately
                      # in each iteration of the list comp. iteration.
                      lambda s,p1=p,q1=q: s.move(p1,q1) )
             for (p,q) in peg_combinations]
#</OPERATORS>

#<GOAL_TEST> (optional)
GOAL_TEST = lambda s: goal_test(s)
#</GOAL_TEST>

#<GOAL_MESSAGE_FUNCTION> (optional)
GOAL_MESSAGE_FUNCTION = lambda s: goal_message(s)
#</GOAL_MESSAGE_FUNCTION>

